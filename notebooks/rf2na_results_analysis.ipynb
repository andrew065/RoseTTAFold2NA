{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb36085",
   "metadata": {},
   "source": [
    "# RoseTTAFold2NA Results Analysis\n",
    "\n",
    "This notebook analyzes the output from RoseTTAFold2NA protein-DNA docking experiments.\n",
    "The model produces a numpy .npz file containing three main outputs:\n",
    "\n",
    "- **dist**: (L x L x 37) - Predicted distogram\n",
    "- **lddt**: (L) - Per-residue predicted local distance difference test (confidence score)\n",
    "- **pae**: (L x L) - Per-residue pair predicted aligned error\n",
    "\n",
    "Where L is the complex length (protein + DNA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fe2f4",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the numpy .npz file containing the RoseTTAFold2NA predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af01497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your .npz file\n",
    "# Update this path to point to your actual results file\n",
    "npz_file_path = \"../experiments/test_docking_20628006/models/model_00.npz\"\n",
    "\n",
    "# Check if file exists\n",
    "if not Path(npz_file_path).exists():\n",
    "    print(f\"File not found: {npz_file_path}\")\n",
    "    print(\"Please update the npz_file_path variable to point to your actual results file.\")\n",
    "    print(\"\\nExample experiment directories:\")\n",
    "    experiment_dir = Path(\"../experiments\")\n",
    "    if experiment_dir.exists():\n",
    "        for exp in experiment_dir.iterdir():\n",
    "            if exp.is_dir():\n",
    "                models_dir = exp / \"models\"\n",
    "                if models_dir.exists():\n",
    "                    npz_files = list(models_dir.glob(\"*.npz\"))\n",
    "                    if npz_files:\n",
    "                        print(f\"  {exp.name}/models/{npz_files[0].name}\")\n",
    "else:\n",
    "    # Load the data\n",
    "    data = np.load(npz_file_path)\n",
    "    print(f\"Successfully loaded: {npz_file_path}\")\n",
    "    \n",
    "    # Display available keys in the file\n",
    "    print(f\"\\nAvailable keys in the file: {list(data.keys())}\")\n",
    "    \n",
    "    # Extract the three main arrays\n",
    "    dist = data['dist']  # Distogram (L x L x 37)\n",
    "    lddt = data['lddt']  # Per-residue confidence (L)\n",
    "    pae = data['pae']    # Predicted aligned error (L x L)\n",
    "    \n",
    "    # Print shapes\n",
    "    print(f\"\\nData shapes:\")\n",
    "    print(f\"  Distogram (dist): {dist.shape}\")\n",
    "    print(f\"  LDDT confidence (lddt): {lddt.shape}\")\n",
    "    print(f\"  Predicted Aligned Error (pae): {pae.shape}\")\n",
    "    \n",
    "    L = len(lddt)  # Complex length\n",
    "    print(f\"\\nComplex length (L): {L} residues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0cd12",
   "metadata": {},
   "source": [
    "## 1. LDDT Confidence Analysis\n",
    "\n",
    "The Local Distance Difference Test (LDDT) provides a per-residue confidence score.\n",
    "Higher values indicate higher confidence in the predicted structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbd9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lddt' in locals():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot 1: LDDT confidence along sequence\n",
    "    ax1.plot(range(1, L+1), lddt, linewidth=2, color='blue', alpha=0.7)\n",
    "    ax1.fill_between(range(1, L+1), lddt, alpha=0.3, color='blue')\n",
    "    ax1.set_xlabel('Residue Position')\n",
    "    ax1.set_ylabel('LDDT Confidence Score')\n",
    "    ax1.set_title('Per-Residue Confidence (LDDT)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # Add confidence threshold lines\n",
    "    ax1.axhline(y=0.9, color='green', linestyle='--', alpha=0.7, label='Very High (>0.9)')\n",
    "    ax1.axhline(y=0.7, color='orange', linestyle='--', alpha=0.7, label='High (>0.7)')\n",
    "    ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Medium (>0.5)')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot 2: LDDT distribution histogram\n",
    "    ax2.hist(lddt, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax2.set_xlabel('LDDT Confidence Score')\n",
    "    ax2.set_ylabel('Number of Residues')\n",
    "    ax2.set_title('Distribution of LDDT Confidence Scores')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics text\n",
    "    mean_lddt = np.mean(lddt)\n",
    "    median_lddt = np.median(lddt)\n",
    "    min_lddt = np.min(lddt)\n",
    "    max_lddt = np.max(lddt)\n",
    "    \n",
    "    stats_text = f'Mean: {mean_lddt:.3f}\\nMedian: {median_lddt:.3f}\\nMin: {min_lddt:.3f}\\nMax: {max_lddt:.3f}'\n",
    "    ax2.text(0.02, 0.98, stats_text, transform=ax2.transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"LDDT Confidence Summary:\")\n",
    "    print(f\"  Mean confidence: {mean_lddt:.3f}\")\n",
    "    print(f\"  Median confidence: {median_lddt:.3f}\")\n",
    "    print(f\"  Standard deviation: {np.std(lddt):.3f}\")\n",
    "    print(f\"  Residues with very high confidence (>0.9): {np.sum(lddt > 0.9)} ({100*np.sum(lddt > 0.9)/L:.1f}%)\")\n",
    "    print(f\"  Residues with high confidence (>0.7): {np.sum(lddt > 0.7)} ({100*np.sum(lddt > 0.7)/L:.1f}%)\")\n",
    "    print(f\"  Residues with low confidence (<0.5): {np.sum(lddt < 0.5)} ({100*np.sum(lddt < 0.5)/L:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d4734",
   "metadata": {},
   "source": [
    "## 2. Predicted Aligned Error (PAE) Analysis\n",
    "\n",
    "The PAE matrix shows the predicted error between pairs of residues.\n",
    "Lower values (darker colors) indicate higher confidence in the relative positioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115b5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pae' in locals():\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    \n",
    "    # Plot 1: Full PAE heatmap\n",
    "    im1 = ax1.imshow(pae, cmap='viridis_r', aspect='equal')\n",
    "    ax1.set_title('Predicted Aligned Error (PAE) Matrix')\n",
    "    ax1.set_xlabel('Residue j')\n",
    "    ax1.set_ylabel('Residue i')\n",
    "    cbar1 = plt.colorbar(im1, ax=ax1, shrink=0.8)\n",
    "    cbar1.set_label('PAE (Ångström)', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Plot 2: PAE with custom colormap for better interpretation\n",
    "    im2 = ax2.imshow(pae, cmap='RdYlBu_r', aspect='equal', vmin=0, vmax=np.percentile(pae, 95))\n",
    "    ax2.set_title('PAE Matrix (Clipped at 95th percentile)')\n",
    "    ax2.set_xlabel('Residue j')\n",
    "    ax2.set_ylabel('Residue i')\n",
    "    cbar2 = plt.colorbar(im2, ax=ax2, shrink=0.8)\n",
    "    cbar2.set_label('PAE (Ångström)', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Plot 3: PAE distribution\n",
    "    ax3.hist(pae.flatten(), bins=50, alpha=0.7, color='coral', edgecolor='black')\n",
    "    ax3.set_xlabel('PAE (Ångström)')\n",
    "    ax3.set_ylabel('Frequency')\n",
    "    ax3.set_title('Distribution of PAE Values')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Average PAE per residue\n",
    "    avg_pae_per_residue = np.mean(pae, axis=1)\n",
    "    ax4.plot(range(1, L+1), avg_pae_per_residue, linewidth=2, color='red', alpha=0.7)\n",
    "    ax4.fill_between(range(1, L+1), avg_pae_per_residue, alpha=0.3, color='red')\n",
    "    ax4.set_xlabel('Residue Position')\n",
    "    ax4.set_ylabel('Average PAE (Ångström)')\n",
    "    ax4.set_title('Average PAE per Residue')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print PAE statistics\n",
    "    mean_pae = np.mean(pae)\n",
    "    median_pae = np.median(pae)\n",
    "    min_pae = np.min(pae)\n",
    "    max_pae = np.max(pae)\n",
    "    \n",
    "    print(f\"PAE Summary:\")\n",
    "    print(f\"  Mean PAE: {mean_pae:.2f} Ångström\")\n",
    "    print(f\"  Median PAE: {median_pae:.2f} Ångström\")\n",
    "    print(f\"  Standard deviation: {np.std(pae):.2f} Ångström\")\n",
    "    print(f\"  Min PAE: {min_pae:.2f} Ångström\")\n",
    "    print(f\"  Max PAE: {max_pae:.2f} Ångström\")\n",
    "    print(f\"  95th percentile: {np.percentile(pae, 95):.2f} Ångström\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40612f18",
   "metadata": {},
   "source": [
    "## 3. Distogram Analysis\n",
    "\n",
    "The distogram contains predicted distance distributions for all residue pairs.\n",
    "It has 37 distance bins representing different distance ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4449609",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dist' in locals():\n",
    "    # Distance bins (common RoseTTAFold2NA distance bins in Ångström)\n",
    "    # These are approximate bins - adjust if you know the exact binning used\n",
    "    distance_bins = np.linspace(2, 22, 37)  # 37 bins from 2Å to 22Å\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    \n",
    "    # Plot 1: Most probable distances (argmax of distogram)\n",
    "    most_probable_distances = distance_bins[np.argmax(dist, axis=2)]\n",
    "    im1 = ax1.imshow(most_probable_distances, cmap='plasma', aspect='equal')\n",
    "    ax1.set_title('Most Probable Distances from Distogram')\n",
    "    ax1.set_xlabel('Residue j')\n",
    "    ax1.set_ylabel('Residue i')\n",
    "    cbar1 = plt.colorbar(im1, ax=ax1, shrink=0.8)\n",
    "    cbar1.set_label('Distance (Ångström)', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Plot 2: Confidence in distance predictions (max probability)\n",
    "    distance_confidence = np.max(dist, axis=2)\n",
    "    im2 = ax2.imshow(distance_confidence, cmap='viridis', aspect='equal')\n",
    "    ax2.set_title('Distance Prediction Confidence')\n",
    "    ax2.set_xlabel('Residue j')\n",
    "    ax2.set_ylabel('Residue i')\n",
    "    cbar2 = plt.colorbar(im2, ax=ax2, shrink=0.8)\n",
    "    cbar2.set_label('Max Probability', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Plot 3: Example distance distribution for a residue pair\n",
    "    # Choose a pair near the middle of the sequence\n",
    "    i, j = L//4, 3*L//4\n",
    "    ax3.bar(distance_bins, dist[i, j, :], alpha=0.7, color='green', edgecolor='black', width=0.4)\n",
    "    ax3.set_xlabel('Distance (Ångström)')\n",
    "    ax3.set_ylabel('Probability')\n",
    "    ax3.set_title(f'Distance Distribution for Residue Pair ({i+1}, {j+1})')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight the most probable distance\n",
    "    max_idx = np.argmax(dist[i, j, :])\n",
    "    ax3.axvline(distance_bins[max_idx], color='red', linestyle='--', \n",
    "                label=f'Most probable: {distance_bins[max_idx]:.1f}Å')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # Plot 4: Distribution of most probable distances\n",
    "    ax4.hist(most_probable_distances[np.triu_indices(L, k=1)], bins=30, \n",
    "             alpha=0.7, color='orange', edgecolor='black')\n",
    "    ax4.set_xlabel('Most Probable Distance (Ångström)')\n",
    "    ax4.set_ylabel('Number of Residue Pairs')\n",
    "    ax4.set_title('Distribution of Most Probable Distances')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print distogram statistics\n",
    "    upper_triangle = np.triu_indices(L, k=1)\n",
    "    mean_distance = np.mean(most_probable_distances[upper_triangle])\n",
    "    median_distance = np.median(most_probable_distances[upper_triangle])\n",
    "    mean_confidence = np.mean(distance_confidence[upper_triangle])\n",
    "    \n",
    "    print(f\"Distogram Summary:\")\n",
    "    print(f\"  Mean predicted distance: {mean_distance:.2f} Ångström\")\n",
    "    print(f\"  Median predicted distance: {median_distance:.2f} Ångström\")\n",
    "    print(f\"  Mean distance prediction confidence: {mean_confidence:.3f}\")\n",
    "    print(f\"  Number of distance bins: {dist.shape[2]}\")\n",
    "    print(f\"  Distance range: {distance_bins[0]:.1f} - {distance_bins[-1]:.1f} Ångström\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16eb993",
   "metadata": {},
   "source": [
    "## 4. Contact Map Analysis\n",
    "\n",
    "Generate contact maps based on predicted distances to identify likely contacts between residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dist' in locals():\n",
    "    # Define contact thresholds\n",
    "    contact_threshold_8A = 8.0   # Strong contacts\n",
    "    contact_threshold_12A = 12.0 # Medium-range contacts\n",
    "    \n",
    "    # Calculate contact probabilities\n",
    "    # Sum probabilities for distances below threshold\n",
    "    contact_prob_8A = np.sum(dist[:, :, distance_bins <= contact_threshold_8A], axis=2)\n",
    "    contact_prob_12A = np.sum(dist[:, :, distance_bins <= contact_threshold_12A], axis=2)\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    \n",
    "    # Plot 1: Contact map for 8Å threshold\n",
    "    im1 = ax1.imshow(contact_prob_8A, cmap='Reds', aspect='equal')\n",
    "    ax1.set_title(f'Contact Probability Map (≤{contact_threshold_8A}Å)')\n",
    "    ax1.set_xlabel('Residue j')\n",
    "    ax1.set_ylabel('Residue i')\n",
    "    cbar1 = plt.colorbar(im1, ax=ax1, shrink=0.8)\n",
    "    cbar1.set_label('Contact Probability', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Plot 2: Contact map for 12Å threshold\n",
    "    im2 = ax2.imshow(contact_prob_12A, cmap='Blues', aspect='equal')\n",
    "    ax2.set_title(f'Contact Probability Map (≤{contact_threshold_12A}Å)')\n",
    "    ax2.set_xlabel('Residue j')\n",
    "    ax2.set_ylabel('Residue i')\n",
    "    cbar2 = plt.colorbar(im2, ax=ax2, shrink=0.8)\n",
    "    cbar2.set_label('Contact Probability', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Plot 3: Binary contact map (high confidence contacts)\n",
    "    high_confidence_contacts = (contact_prob_8A > 0.5) & (np.arange(L)[:, None] != np.arange(L))\n",
    "    ax3.imshow(high_confidence_contacts, cmap='RdBu_r', aspect='equal')\n",
    "    ax3.set_title('High Confidence Contacts (>0.5 prob, ≤8Å)')\n",
    "    ax3.set_xlabel('Residue j')\n",
    "    ax3.set_ylabel('Residue i')\n",
    "    \n",
    "    # Plot 4: Contact order analysis\n",
    "    # Calculate sequence separation for contacts\n",
    "    contact_pairs = np.where(high_confidence_contacts)\n",
    "    if len(contact_pairs[0]) > 0:\n",
    "        sequence_separations = np.abs(contact_pairs[0] - contact_pairs[1])\n",
    "        ax4.hist(sequence_separations, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "        ax4.set_xlabel('Sequence Separation')\n",
    "        ax4.set_ylabel('Number of Contacts')\n",
    "        ax4.set_title('Contact Order Distribution')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        short_range = np.sum(sequence_separations <= 12)\n",
    "        medium_range = np.sum((sequence_separations > 12) & (sequence_separations <= 24))\n",
    "        long_range = np.sum(sequence_separations > 24)\n",
    "        \n",
    "        ax4.text(0.98, 0.98, f'Short-range (≤12): {short_range}\\n' + \n",
    "                            f'Medium-range (13-24): {medium_range}\\n' + \n",
    "                            f'Long-range (>24): {long_range}',\n",
    "                transform=ax4.transAxes, verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No high confidence contacts found', \n",
    "                transform=ax4.transAxes, ha='center', va='center')\n",
    "        ax4.set_title('Contact Order Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print contact statistics\n",
    "    total_contacts_8A = np.sum(contact_prob_8A > 0.5) - L  # Subtract diagonal\n",
    "    total_contacts_12A = np.sum(contact_prob_12A > 0.5) - L\n",
    "    \n",
    "    print(f\"Contact Analysis Summary:\")\n",
    "    print(f\"  High confidence contacts (≤8Å, >0.5 prob): {total_contacts_8A}\")\n",
    "    print(f\"  Medium confidence contacts (≤12Å, >0.5 prob): {total_contacts_12A}\")\n",
    "    print(f\"  Average 8Å contact probability: {np.mean(contact_prob_8A[contact_prob_8A > 0]):.3f}\")\n",
    "    print(f\"  Average 12Å contact probability: {np.mean(contact_prob_12A[contact_prob_12A > 0]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6bb3c",
   "metadata": {},
   "source": [
    "## 5. Overall Model Quality Summary\n",
    "\n",
    "Combine all metrics to provide an overall assessment of the predicted structure quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(var in locals() for var in ['lddt', 'pae', 'dist']):\n",
    "    # Calculate overall quality metrics\n",
    "    high_confidence_residues = np.sum(lddt > 0.7) / L\n",
    "    low_pae_pairs = np.sum(pae < 5) / (L * L)\n",
    "    mean_lddt = np.mean(lddt)\n",
    "    mean_pae = np.mean(pae)\n",
    "    \n",
    "    # Create a summary plot\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Quality vs sequence position\n",
    "    ax1_twin = ax1.twinx()\n",
    "    line1 = ax1.plot(range(1, L+1), lddt, 'b-', alpha=0.7, linewidth=2, label='LDDT')\n",
    "    line2 = ax1_twin.plot(range(1, L+1), np.mean(pae, axis=1), 'r-', alpha=0.7, linewidth=2, label='Avg PAE')\n",
    "    \n",
    "    ax1.set_xlabel('Residue Position')\n",
    "    ax1.set_ylabel('LDDT Confidence', color='b')\n",
    "    ax1_twin.set_ylabel('Average PAE (Ångström)', color='r')\n",
    "    ax1.set_title('Structure Quality Along Sequence')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Combine legends\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='upper right')\n",
    "    \n",
    "    # Plot 2: Quality correlation\n",
    "    avg_pae_per_residue = np.mean(pae, axis=1)\n",
    "    ax2.scatter(lddt, avg_pae_per_residue, alpha=0.6, s=30)\n",
    "    ax2.set_xlabel('LDDT Confidence')\n",
    "    ax2.set_ylabel('Average PAE (Ångström)')\n",
    "    ax2.set_title('LDDT vs PAE Correlation')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    correlation = np.corrcoef(lddt, avg_pae_per_residue)[0, 1]\n",
    "    ax2.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "             transform=ax2.transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Plot 3: Combined confidence heatmap\n",
    "    # Create a combined confidence score: high LDDT (both residues) and low PAE\n",
    "    lddt_matrix = lddt[:, None] * lddt[None, :]\n",
    "    combined_confidence = lddt_matrix * np.exp(-pae / 10)  # Exponential decay for PAE\n",
    "    \n",
    "    im3 = ax3.imshow(combined_confidence, cmap='RdYlBu_r', aspect='equal')\n",
    "    ax3.set_title('Combined Confidence Score')\n",
    "    ax3.set_xlabel('Residue j')\n",
    "    ax3.set_ylabel('Residue i')\n",
    "    cbar3 = plt.colorbar(im3, ax=ax3, shrink=0.8)\n",
    "    cbar3.set_label('Combined Score', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Plot 4: Quality metrics summary\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Create quality assessment\n",
    "    if mean_lddt > 0.8:\n",
    "        lddt_assessment = \"Excellent\"\n",
    "        lddt_color = \"green\"\n",
    "    elif mean_lddt > 0.6:\n",
    "        lddt_assessment = \"Good\"\n",
    "        lddt_color = \"orange\"\n",
    "    else:\n",
    "        lddt_assessment = \"Poor\"\n",
    "        lddt_color = \"red\"\n",
    "    \n",
    "    if mean_pae < 5:\n",
    "        pae_assessment = \"Excellent\"\n",
    "        pae_color = \"green\"\n",
    "    elif mean_pae < 10:\n",
    "        pae_assessment = \"Good\"\n",
    "        pae_color = \"orange\"\n",
    "    else:\n",
    "        pae_assessment = \"Poor\"\n",
    "        pae_color = \"red\"\n",
    "    \n",
    "    # Display summary statistics\n",
    "    summary_text = f\"\"\"\n",
    "MODEL QUALITY SUMMARY\n",
    "{'='*50}\n",
    "\n",
    "Complex Length: {L} residues\n",
    "\n",
    "CONFIDENCE METRICS:\n",
    "• Mean LDDT: {mean_lddt:.3f} ({lddt_assessment})\n",
    "• Residues with high confidence (>0.7): {high_confidence_residues:.1%}\n",
    "• Residues with very high confidence (>0.9): {np.sum(lddt > 0.9)/L:.1%}\n",
    "\n",
    "PREDICTED ALIGNED ERROR:\n",
    "• Mean PAE: {mean_pae:.2f} Ångström ({pae_assessment})\n",
    "• Residue pairs with low error (<5Å): {low_pae_pairs:.1%}\n",
    "• Median PAE: {np.median(pae):.2f} Ångström\n",
    "\n",
    "STRUCTURAL FEATURES:\n",
    "• High confidence contacts (≤8Å): {np.sum(contact_prob_8A > 0.5) - L}\n",
    "• Mean predicted distance: {np.mean(most_probable_distances[np.triu_indices(L, k=1)]):.2f} Ångström\n",
    "• LDDT-PAE correlation: {correlation:.3f}\n",
    "\n",
    "OVERALL ASSESSMENT:\n",
    "{'Good quality model' if mean_lddt > 0.7 and mean_pae < 8 else 'Moderate quality model' if mean_lddt > 0.5 else 'Low quality model'}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, \n",
    "             verticalalignment='top', fontfamily='monospace', fontsize=11,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Analysis complete! The plots above provide a comprehensive view of your RoseTTAFold2NA predictions.\")\n",
    "    print(\"\\nKey takeaways:\")\n",
    "    print(f\"• Overall model quality: {'Good' if mean_lddt > 0.7 and mean_pae < 8 else 'Moderate' if mean_lddt > 0.5 else 'Poor'}\")\n",
    "    print(f\"• {high_confidence_residues:.1%} of residues have high confidence (LDDT > 0.7)\")\n",
    "    print(f\"• Mean predicted aligned error is {mean_pae:.2f} Ångström\")\n",
    "    print(f\"• {np.sum(contact_prob_8A > 0.5) - L} high-confidence contacts identified\")\n",
    "else:\n",
    "    print(\"Please load the data first by running the 'Load Data' cell above.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
